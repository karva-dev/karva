{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"Karva (0.0.1-alpha.4)","text":"<p>A Python test framework, written in Rust.</p> <p>We'd love for you to try Karva! It's currently in alpha, and your feedback helps shape the project. Get started or join us on Discord.</p>","path":["Karva (0.0.1-alpha.4)"],"tags":[]},{"location":"#about-karva","level":2,"title":"About Karva","text":"<p>Karva aims to be an efficient alternative to <code>pytest</code> and <code>unittest</code>.</p> <p>While we do not yet support all of pytest's features, we aim to gradually add support for pytest alternatives as we add features.</p>","path":["Karva (0.0.1-alpha.4)"],"tags":[]},{"location":"#getting-started","level":2,"title":"Getting started","text":"","path":["Karva (0.0.1-alpha.4)"],"tags":[]},{"location":"#installation","level":3,"title":"Installation","text":"<p>Karva is available as <code>karva</code> on PyPI.</p> <p>Use karva directly with <code>uvx</code>:</p> Bash<pre><code>uvx karva test\nuvx karva version\n</code></pre> <p>Or install karva with <code>uv</code>, or <code>pip</code>:</p> Bash<pre><code># With uv.\nuv tool install karva@latest\n\n# Add karva to your project.\nuv add --dev karva\n\n# With pip.\npip install karva\n</code></pre>","path":["Karva (0.0.1-alpha.4)"],"tags":[]},{"location":"#usage","level":3,"title":"Usage","text":"<p>By default, Karva will respect your <code>.gitignore</code> files when discovering tests in specified directories.</p> <p>To run your tests, try any of the following:</p> Bash<pre><code># Run all tests.\nkarva test\n\n# Run tests in a specific directory.\nkarva test tests/\n\n# Run tests in a specific file.\nkarva test tests/test_example.py\n</code></pre>","path":["Karva (0.0.1-alpha.4)"],"tags":[]},{"location":"#example","level":4,"title":"Example","text":"<p>Here is a small example of using karva, as you can see it works just like pytest.</p> tests/test.py<pre><code>def test_pass():\n    assert True\n\n\ndef test_fail():\n    assert False, \"This test should fail\"\n</code></pre> <p>Running karva:</p> Bash<pre><code>uv run karva test tests/\n</code></pre> <p>Provides the following output:</p> Text Only<pre><code>test tests.test::test_pass ... ok\ntest tests.test::test_fail ... FAILED\n\ndiagnostics:\n\nerror[test-failure]: Test `test_fail` failed\n --&gt; tests/test.py:5:5\n  |\n5 | def test_fail():\n  |     ^^^^^^^^^\n6 |     assert False, \"This test should fail\"\n  |\ninfo: Test failed here\n --&gt; tests/test.py:6:5\n  |\n5 | def test_fail():\n6 |     assert False, \"This test should fail\"\n  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  |\ninfo: Error message: This test should fail\n\ntest result: FAILED. 1 passed; 1 failed; 0 skipped; finished in 8ms\n</code></pre>","path":["Karva (0.0.1-alpha.4)"],"tags":[]},{"location":"#contributing","level":2,"title":"Contributing","text":"<p>Contributions are welcome! See CONTRIBUTING.md for more information.</p> <p>You can also join us on Discord</p>","path":["Karva (0.0.1-alpha.4)"],"tags":[]},{"location":"cli/","level":1,"title":"CLI Reference","text":"","path":["CLI Reference"],"tags":[]},{"location":"cli/#cli-reference","level":1,"title":"CLI Reference","text":"","path":["CLI Reference"],"tags":[]},{"location":"cli/#karva","level":2,"title":"karva","text":"<p>A Python test runner.</p> Usage Text Only<pre><code>karva &lt;COMMAND&gt;\n</code></pre> Commands <code>karva test</code><p>Run tests</p> <code>karva snapshot</code><p>Manage snapshots created by <code>karva.assert_snapshot()</code></p> <code>karva version</code><p>Display Karva's version</p> <code>karva help</code><p>Print this message or the help of the given subcommand(s)</p>","path":["CLI Reference"],"tags":[]},{"location":"cli/#karva-test","level":2,"title":"karva test","text":"<p>Run tests</p> Usage Text Only<pre><code>karva test [OPTIONS] [PATH]...\n</code></pre> Arguments <code>PATHS</code><p>List of files, directories, or test functions to test [default: the project root]</p> Options <code>--color</code> color<p>Control when colored output is used</p> <p>Possible values:</p> <ul> <li><code>auto</code>:  Display colors if the output goes to an interactive terminal</li> <li><code>always</code>:  Always display colors</li> <li><code>never</code>:  Never display colors</li> </ul><code>--config-file</code> path<p>The path to a <code>karva.toml</code> file to use for configuration.</p> <p>While karva configuration can be included in a <code>pyproject.toml</code> file, it is not allowed in this context.</p> <p>May also be set with the <code>KARVA_CONFIG_FILE</code> environment variable.</p><code>--dry-run</code><p>Print discovered tests without executing them</p> <code>--fail-fast</code><p>When set, the test will fail immediately if any test fails.</p> <p>This only works when running tests in parallel.</p> <code>--help</code>, <code>-h</code><p>Print help (see a summary with '-h')</p> <code>--match</code>, <code>-m</code> name-patterns<p>Filter tests by name using a regular expression.</p> <p>Only tests whose fully qualified name matches the pattern will run. Uses partial matching (the pattern can match anywhere in the name). When specified multiple times, a test runs if it matches any of the patterns.</p> <p>Examples: <code>-m auth</code>, <code>-m '^test::test_login'</code>, <code>-m 'slow|fast'</code>.</p> <code>--no-cache</code><p>Disable reading the karva cache for test duration history</p> <code>--no-ignore</code><p>When set, .gitignore files will not be respected</p> <code>--no-parallel</code><p>Disable parallel execution (equivalent to <code>--num-workers 1</code>)</p> <code>--no-progress</code><p>When set, we will not show individual test case results during execution</p> <code>--num-workers</code>, <code>-n</code> num-workers<p>Number of parallel workers (default: number of CPU cores)</p> <code>--output-format</code> output-format<p>The format to use for printing diagnostic messages</p> <p>Possible values:</p> <ul> <li><code>full</code>:  Print diagnostics verbosely, with context and helpful hints (default)</li> <li><code>concise</code>:  Print diagnostics concisely, one per line</li> </ul><code>--quiet</code>, <code>-q</code><p>Use quiet output (or <code>-qq</code> for silent output)</p> <code>--retry</code> retry<p>When set, the test will retry failed tests up to this number of times</p> <code>--snapshot-update</code><p>Update snapshots directly instead of creating pending <code>.snap.new</code> files.</p> <p>When set, <code>karva.assert_snapshot()</code> will write directly to <code>.snap</code> files, accepting any changes automatically.</p> <code>--tag</code>, <code>-t</code> tag-expressions<p>Filter tests by tag expression. Only tests with matching custom tags will run.</p> <p>Expressions support <code>and</code>, <code>or</code>, <code>not</code>, and parentheses for grouping. When specified multiple times, a test runs if it matches any of the expressions.</p> <p>Examples: <code>-t slow</code>, <code>-t 'not slow'</code>, <code>-t 'slow and integration'</code>, <code>-t 'slow or integration'</code>, <code>-t '(slow or fast) and not flaky'</code>.</p> <code>--test-prefix</code> test-prefix<p>The prefix of the test functions</p> <code>--try-import-fixtures</code><p>When set, we will try to import functions in each test file as well as parsing the ast to find them.</p> <p>This is often slower, so it is not recommended for most projects.</p> <code>--verbose</code>, <code>-v</code><p>Use verbose output (or <code>-vv</code> and <code>-vvv</code> for more verbose output)</p> <code>--watch</code><p>Re-run tests when Python source files change</p>","path":["CLI Reference"],"tags":[]},{"location":"cli/#karva-snapshot","level":2,"title":"karva snapshot","text":"<p>Manage snapshots created by <code>karva.assert_snapshot()</code></p> Usage Text Only<pre><code>karva snapshot &lt;COMMAND&gt;\n</code></pre> Commands <code>karva snapshot accept</code><p>Accept all (or filtered) pending snapshots</p> <code>karva snapshot reject</code><p>Reject all (or filtered) pending snapshots</p> <code>karva snapshot pending</code><p>List pending snapshots</p> <code>karva snapshot review</code><p>Interactively review pending snapshots</p> <code>karva snapshot prune</code><p>Remove snapshot files whose source test no longer exists</p> <code>karva snapshot delete</code><p>Delete all (or filtered) snapshot files (.snap and .snap.new)</p> <code>karva snapshot help</code><p>Print this message or the help of the given subcommand(s)</p>","path":["CLI Reference"],"tags":[]},{"location":"cli/#karva-snapshot-accept","level":3,"title":"karva snapshot acceptUsageArgumentsOptions","text":"<p>Accept all (or filtered) pending snapshots</p> Text Only<pre><code>karva snapshot accept [PATH]...\n</code></pre> <code>PATHS</code><p>Optional paths to filter snapshots by directory or file</p> <code>--help</code>, <code>-h</code><p>Print help</p>","path":["CLI Reference"],"tags":[]},{"location":"cli/#karva-snapshot-reject","level":3,"title":"karva snapshot rejectUsageArgumentsOptions","text":"<p>Reject all (or filtered) pending snapshots</p> Text Only<pre><code>karva snapshot reject [PATH]...\n</code></pre> <code>PATHS</code><p>Optional paths to filter snapshots by directory or file</p> <code>--help</code>, <code>-h</code><p>Print help</p>","path":["CLI Reference"],"tags":[]},{"location":"cli/#karva-snapshot-pending","level":3,"title":"karva snapshot pendingUsageArgumentsOptions","text":"<p>List pending snapshots</p> Text Only<pre><code>karva snapshot pending [PATH]...\n</code></pre> <code>PATHS</code><p>Optional paths to filter snapshots by directory or file</p> <code>--help</code>, <code>-h</code><p>Print help</p>","path":["CLI Reference"],"tags":[]},{"location":"cli/#karva-snapshot-review","level":3,"title":"karva snapshot reviewUsageArgumentsOptions","text":"<p>Interactively review pending snapshots</p> Text Only<pre><code>karva snapshot review [PATH]...\n</code></pre> <code>PATHS</code><p>Optional paths to filter snapshots by directory or file</p> <code>--help</code>, <code>-h</code><p>Print help</p>","path":["CLI Reference"],"tags":[]},{"location":"cli/#karva-snapshot-prune","level":3,"title":"karva snapshot pruneUsageArgumentsOptions","text":"<p>Remove snapshot files whose source test no longer exists</p> Text Only<pre><code>karva snapshot prune [OPTIONS] [PATH]...\n</code></pre> <code>PATHS</code><p>Optional paths to filter snapshots by directory or file</p> <code>--dry-run</code><p>Show which snapshots would be removed without deleting them</p> <code>--help</code>, <code>-h</code><p>Print help</p>","path":["CLI Reference"],"tags":[]},{"location":"cli/#karva-snapshot-delete","level":3,"title":"karva snapshot deleteUsageArgumentsOptions","text":"<p>Delete all (or filtered) snapshot files (.snap and .snap.new)</p> Text Only<pre><code>karva snapshot delete [OPTIONS] [PATH]...\n</code></pre> <code>PATHS</code><p>Optional paths to filter which snapshot files are deleted</p> <code>--dry-run</code><p>Show which snapshot files would be deleted without removing them</p> <code>--help</code>, <code>-h</code><p>Print help</p>","path":["CLI Reference"],"tags":[]},{"location":"cli/#karva-snapshot-help","level":3,"title":"karva snapshot helpUsage","text":"<p>Print this message or the help of the given subcommand(s)</p> Text Only<pre><code>karva snapshot help [COMMAND]\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli/#karva-version","level":2,"title":"karva version","text":"<p>Display Karva's version</p> Usage Text Only<pre><code>karva version\n</code></pre> Options <code>--help</code>, <code>-h</code><p>Print help</p>","path":["CLI Reference"],"tags":[]},{"location":"cli/#karva-help","level":2,"title":"karva help","text":"<p>Print this message or the help of the given subcommand(s)</p> Usage Text Only<pre><code>karva help [COMMAND]\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"configuration/","level":1,"title":"Configuration","text":"","path":["Configuration"],"tags":[]},{"location":"configuration/#configuration","level":1,"title":"Configuration","text":"","path":["Configuration"],"tags":[]},{"location":"configuration/#src","level":2,"title":"<code>src</code>","text":"","path":["Configuration"],"tags":[]},{"location":"configuration/#include","level":3,"title":"<code>include</code>","text":"<p>A list of files and directories to check. Including a file or directory will make it so that it (and its contents) are tested.</p> <ul> <li><code>tests</code> matches a directory named <code>tests</code></li> <li><code>tests/test.py</code> matches a file named <code>test.py</code> in the <code>tests</code> directory</li> </ul> <p>Default value: <code>null</code></p> <p>Type: <code>list[str]</code></p> <p>Example usage (<code>pyproject.toml</code>):</p> TOML<pre><code>[tool.karva.src]\ninclude = [\"tests\"]\n</code></pre>","path":["Configuration"],"tags":[]},{"location":"configuration/#respect-ignore-files","level":3,"title":"<code>respect-ignore-files</code>","text":"<p>Whether to automatically exclude files that are ignored by <code>.ignore</code>, <code>.gitignore</code>, <code>.git/info/exclude</code>, and global <code>gitignore</code> files. Enabled by default.</p> <p>Default value: <code>true</code></p> <p>Type: <code>bool</code></p> <p>Example usage (<code>pyproject.toml</code>):</p> TOML<pre><code>[tool.karva.src]\nrespect-ignore-files = false\n</code></pre>","path":["Configuration"],"tags":[]},{"location":"configuration/#terminal","level":2,"title":"<code>terminal</code>","text":"","path":["Configuration"],"tags":[]},{"location":"configuration/#output-format","level":3,"title":"<code>output-format</code>","text":"<p>The format to use for printing diagnostic messages.</p> <p>Defaults to <code>full</code>.</p> <p>Default value: <code>full</code></p> <p>Type: <code>full | concise</code></p> <p>Example usage (<code>pyproject.toml</code>):</p> TOML<pre><code>[tool.karva.terminal]\noutput-format = \"concise\"\n</code></pre>","path":["Configuration"],"tags":[]},{"location":"configuration/#show-python-output","level":3,"title":"<code>show-python-output</code>","text":"<p>Whether to show the python output.</p> <p>This is the output the <code>print</code> goes to etc.</p> <p>Default value: <code>true</code></p> <p>Type: <code>true | false</code></p> <p>Example usage (<code>pyproject.toml</code>):</p> TOML<pre><code>[tool.karva.terminal]\nshow-python-output = false\n</code></pre>","path":["Configuration"],"tags":[]},{"location":"configuration/#test","level":2,"title":"<code>test</code>","text":"","path":["Configuration"],"tags":[]},{"location":"configuration/#fail-fast","level":3,"title":"<code>fail-fast</code>","text":"<p>Whether to fail fast when a test fails.</p> <p>Defaults to <code>false</code>.</p> <p>Default value: <code>false</code></p> <p>Type: <code>true | false</code></p> <p>Example usage (<code>pyproject.toml</code>):</p> TOML<pre><code>[tool.karva.test]\nfail-fast = true\n</code></pre>","path":["Configuration"],"tags":[]},{"location":"configuration/#retry","level":3,"title":"<code>retry</code>","text":"<p>When set, we will retry failed tests up to this number of times.</p> <p>Default value: <code>0</code></p> <p>Type: <code>u32</code></p> <p>Example usage (<code>pyproject.toml</code>):</p> TOML<pre><code>[tool.karva.test]\nretry = 3\n</code></pre>","path":["Configuration"],"tags":[]},{"location":"configuration/#test-function-prefix","level":3,"title":"<code>test-function-prefix</code>","text":"<p>The prefix to use for test functions.</p> <p>Defaults to <code>test</code>.</p> <p>Default value: <code>test</code></p> <p>Type: <code>string</code></p> <p>Example usage (<code>pyproject.toml</code>):</p> TOML<pre><code>[tool.karva.test]\ntest-function-prefix = \"test\"\n</code></pre>","path":["Configuration"],"tags":[]},{"location":"configuration/#try-import-fixtures","level":3,"title":"<code>try-import-fixtures</code>","text":"<p>When set, we will try to import functions in each test file as well as parsing the ast to find them.</p> <p>This is often slower, so it is not recommended for most projects.</p> <p>Default value: <code>false</code></p> <p>Type: <code>true | false</code></p> <p>Example usage (<code>pyproject.toml</code>):</p> TOML<pre><code>[tool.karva.test]\ntry-import-fixtures = true\n</code></pre>","path":["Configuration"],"tags":[]},{"location":"installation/","level":1,"title":"Installation","text":"<p>Karva is available as <code>karva</code> on PyPI.</p> <p>Use karva directly with <code>uvx</code>:</p> Bash<pre><code>uvx karva test\nuvx karva version\n</code></pre> <p>Or install karva with <code>uv</code>, or <code>pip</code>:</p> Bash<pre><code># With uv.\nuv tool install karva@latest\n\n# Add karva to your project.\nuv add --dev karva\n\n# With pip.\npip install karva\n</code></pre> <p>Once installed, you can use karva to run your tests:</p> Bash<pre><code>karva test\n</code></pre> <p>Or to get the version of karva you're using:</p> Bash<pre><code>karva version\n</code></pre>","path":["Installation"],"tags":[]},{"location":"tutorial/","level":1,"title":"Tutorial","text":"<p>This tutorial will walk you through the basics of using Karva.</p>","path":["Tutorial"],"tags":[]},{"location":"tutorial/#getting-started","level":2,"title":"Getting started","text":"<p>We will first create a new project using <code>uv</code>.</p> Bash<pre><code>uv init --lib .\nmkdir tests\n</code></pre> <p>This will give us a project that looks like this:</p> Text Only<pre><code>.\n├── pyproject.toml\n├── README.md\n├── src\n│   └── karva_test\n│       ├── __init__.py\n│       └── py.typed\n└── tests\n</code></pre> src/calculator/__init__.py<pre><code>class Calculator:\n    def add(self, a: int, b: int) -&gt; int:\n        return a + b\n</code></pre> tests/test_add.py<pre><code>from calculator import Calculator\n\ndef test_add():\n    calculator = Calculator()\n    assert calculator.add(1, 2) == 3\n</code></pre> <p>Then, we'll add karva to our project.</p> Bash<pre><code>uv add --dev karva\n</code></pre> <p>We can then run our tests with <code>uv run karva test</code>.</p> Bash<pre><code>uv run karva test\n</code></pre>","path":["Tutorial"],"tags":[]},{"location":"usage/functions/","level":1,"title":"Functions","text":"","path":["Using Karva","Functions"],"tags":[]},{"location":"usage/functions/#skip","level":2,"title":"Skip","text":"<p>If you want to skip a test when its running, use <code>karva.skip()</code>.</p> test.py<pre><code>import karva\n\ndef test_function():\n    karva.skip()\n</code></pre> <p>You can optionally provide a reason for skipping the test by passing it as an argument to <code>karva.skip()</code>.</p> test.py<pre><code>import karva\n\ndef test_function():\n    karva.skip(\"This test is not ready yet\")\n\ndef test_function2():\n    karva.skip(reason=\"This test is not ready yet\")\n</code></pre> <p>You can still use <code>pytest.skip()</code> to skip tests.</p>","path":["Using Karva","Functions"],"tags":[]},{"location":"usage/functions/#fail","level":2,"title":"Fail","text":"<p>If you want to fail a test when its running, use <code>karva.fail()</code>.</p> test.py<pre><code>import karva\n\ndef test_function():\n    karva.fail()\n</code></pre> <p>You can optionally provide a reason for failing the test by passing it as an argument to <code>karva.fail()</code>.</p> test.py<pre><code>import karva\n\ndef test_function():\n    karva.fail(\"This test is not ready yet\")\n\ndef test_function2():\n    karva.fail(reason=\"This test is not ready yet\")\n</code></pre> <p>Then running <code>uv run karva test</code> will result in two test fails.</p> <p>You can still use <code>pytest.fail()</code> to fail tests.</p>","path":["Using Karva","Functions"],"tags":[]},{"location":"usage/functions/#raises","level":2,"title":"Raises","text":"<p>If you want to assert that a block of code raises a specific exception, use <code>karva.raises()</code>.</p> test.py<pre><code>import karva\n\ndef test_function():\n    with karva.raises(ValueError):\n        raise ValueError(\"something went wrong\")\n</code></pre> <p>You can optionally provide a <code>match</code> parameter to match a regex pattern against the string representation of the exception.</p> test.py<pre><code>import karva\n\ndef test_function():\n    with karva.raises(ValueError, match=\"something\"):\n        raise ValueError(\"something went wrong\")\n</code></pre> <p>You can access the exception info by using the <code>as</code> keyword. The returned object has <code>type</code>, <code>value</code>, and <code>tb</code> properties.</p> test.py<pre><code>import karva\n\ndef test_function():\n    with karva.raises(ValueError) as exc_info:\n        raise ValueError(\"something went wrong\")\n\n    assert exc_info.type is ValueError\n    assert str(exc_info.value) == \"something went wrong\"\n    assert exc_info.tb is not None\n</code></pre> <p>You can still use <code>pytest.raises()</code> to assert exceptions.</p>","path":["Using Karva","Functions"],"tags":[]},{"location":"usage/snapshots/","level":1,"title":"Snapshots","text":"<p>Snapshot testing captures the output of your code and stores it in a file. On subsequent runs, the output is compared against the stored snapshot. If the output changes, the test fails with a diff showing what changed.</p> <p>This is useful for testing complex outputs like formatted strings, serialized data, or API responses without writing manual assertions.</p>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#basic-usage","level":2,"title":"Basic Usage","text":"<p>Use <code>karva.assert_snapshot()</code> to capture a value as a snapshot.</p> test.py<pre><code>import karva\n\ndef test_greeting():\n    karva.assert_snapshot(\"hello world\")\n</code></pre> <p>The first time you run this test, it will fail and create a pending snapshot file at <code>snapshots/test__test_greeting.snap.new</code>. Accept it to create the baseline:</p> Bash<pre><code>karva snapshot accept\n</code></pre> <p>On subsequent runs, the test passes as long as the output matches the stored snapshot.</p>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#json-snapshots","level":2,"title":"JSON Snapshots","text":"<p>For structured data like dicts and lists, use <code>karva.assert_json_snapshot()</code> for readable, deterministic output. It serializes values using <code>json.dumps(value, sort_keys=True, indent=2)</code>.</p> test.py<pre><code>import karva\n\ndef test_data():\n    data = {\"users\": [\"Alice\", \"Bob\"], \"count\": 2}\n    karva.assert_json_snapshot(data)\n</code></pre> <p>The snapshot stores:</p> JSON<pre><code>{\n  \"count\": 2,\n  \"users\": [\n    \"Alice\",\n    \"Bob\"\n  ]\n}\n</code></pre> <p><code>assert_json_snapshot</code> supports all the same features as <code>assert_snapshot</code>: inline snapshots, <code>--snapshot-update</code>, filters via <code>snapshot_settings</code>, and the pending/accept workflow.</p> test.py<pre><code>import karva\n\ndef test_inline():\n    karva.assert_json_snapshot({\"a\": 1}, inline='{\\n  \"a\": 1\\n}')\n</code></pre> <p>If the value is not JSON-serializable (e.g., a custom object without a default serializer), Python's <code>json</code> module raises a <code>TypeError</code>.</p>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#named-snapshots","level":2,"title":"Named Snapshots","text":"<p>By default, each snapshot is named after the test function. If a test contains more than one unnamed <code>assert_snapshot()</code> call, karva raises an error:</p> Text Only<pre><code>Multiple unnamed snapshots in one test. Use 'name=' for each,\nor wrap in 'karva.snapshot_settings(allow_duplicates=True)'\n</code></pre> <p>Use the <code>name</code> parameter to give each snapshot a distinct name:</p> test.py<pre><code>import karva\n\ndef test_page():\n    karva.assert_snapshot(\"&lt;h1&gt;Title&lt;/h1&gt;\", name=\"header\")\n    karva.assert_snapshot(\"&lt;p&gt;Body text&lt;/p&gt;\", name=\"body\")\n    karva.assert_snapshot(\"&lt;footer&gt;2024&lt;/footer&gt;\", name=\"footer\")\n</code></pre> <p>This creates three separate snapshot files:</p> <ul> <li><code>snapshots/test__test_page--header.snap</code></li> <li><code>snapshots/test__test_page--body.snap</code></li> <li><code>snapshots/test__test_page--footer.snap</code></li> </ul> <p>Alternatively, wrap the calls in <code>snapshot_settings(allow_duplicates=True)</code> to opt in to auto-numbered unnamed snapshots (<code>test_page-0</code>, <code>test_page-1</code>, <code>test_page-2</code>):</p> test.py<pre><code>import karva\n\ndef test_page():\n    with karva.snapshot_settings(allow_duplicates=True):\n        karva.assert_snapshot(\"&lt;h1&gt;Title&lt;/h1&gt;\")\n        karva.assert_snapshot(\"&lt;p&gt;Body text&lt;/p&gt;\")\n        karva.assert_snapshot(\"&lt;footer&gt;2024&lt;/footer&gt;\")\n</code></pre>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#snapshot-files","level":2,"title":"Snapshot Files","text":"<p>Snapshot files are stored in a <code>snapshots/</code> directory next to your test file. Each file uses YAML frontmatter to record metadata:</p> Text Only<pre><code>---\nsource: test.py:5::test_greeting\n---\nhello world\n</code></pre> <p>The <code>source</code> field records the file, line number, and test name that produced the snapshot.</p> <p>When a test produces a new or changed snapshot, a <code>.snap.new</code> file is created alongside the existing <code>.snap</code> file. This pending file must be explicitly accepted or rejected before the test will pass.</p>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#updating-snapshots","level":2,"title":"Updating Snapshots","text":"<p>When you intentionally change the output of your code, use <code>--snapshot-update</code> to update all snapshots in place without creating pending files:</p> Bash<pre><code>karva test --snapshot-update\n</code></pre> <p>This writes directly to <code>.snap</code> files and the tests pass immediately.</p>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#cli-commands","level":2,"title":"CLI Commands","text":"<p>The <code>karva snapshot</code> subcommand manages pending snapshots.</p>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#accept","level":3,"title":"accept","text":"<p>Accept all pending snapshots, promoting <code>.snap.new</code> files to <code>.snap</code>:</p> Bash<pre><code>karva snapshot accept\n</code></pre>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#reject","level":3,"title":"reject","text":"<p>Reject all pending snapshots, deleting the <code>.snap.new</code> files:</p> Bash<pre><code>karva snapshot reject\n</code></pre>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#pending","level":3,"title":"pending","text":"<p>List all pending snapshots:</p> Bash<pre><code>karva snapshot pending\n</code></pre>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#review","level":3,"title":"review","text":"<p>Interactively review each pending snapshot one at a time:</p> Bash<pre><code>karva snapshot review\n</code></pre> <p>For each snapshot, you can:</p> <ul> <li>a -- accept (keep the new snapshot)</li> <li>r -- reject (retain the old snapshot)</li> <li>s -- skip (keep both for now)</li> <li>i -- toggle extended info display</li> <li>d -- toggle diff display</li> </ul> <p>Use uppercase A, R, or S to apply the action to all remaining snapshots.</p> <p>All commands accept optional path arguments to filter which snapshots are affected:</p> Bash<pre><code>karva snapshot accept tests/api/\nkarva snapshot review tests/test_output.py\n</code></pre>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#parametrized-tests","level":2,"title":"Parametrized Tests","text":"<p>Snapshot testing works with parametrized tests. Each parameter combination gets its own snapshot file.</p> test.py<pre><code>import karva\n\n@karva.tags.parametrize(\"name\", [\"Alice\", \"Bob\"])\ndef test_greet(name):\n    karva.assert_snapshot(f\"Hello, {name}!\")\n</code></pre> <p>This creates:</p> <ul> <li><code>snapshots/test__test_greet(name=Alice).snap</code></li> <li><code>snapshots/test__test_greet(name=Bob).snap</code></li> </ul> <p>Named snapshots in parametrized tests combine both:</p> test.py<pre><code>import karva\n\n@karva.tags.parametrize(\"lang\", [\"en\", \"fr\"])\ndef test_translate(lang):\n    karva.assert_snapshot(translate(\"hello\", lang), name=\"greeting\")\n</code></pre> <p>This creates:</p> <ul> <li><code>snapshots/test__test_translate--greeting(lang=en).snap</code></li> <li><code>snapshots/test__test_translate--greeting(lang=fr).snap</code></li> </ul>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#filters","level":2,"title":"Filters","text":"<p>Snapshot output often contains non-deterministic values like timestamps, UUIDs, or file paths that change between runs. Use <code>karva.snapshot_settings()</code> to replace these with stable placeholders before comparison.</p> test.py<pre><code>import karva\n\ndef test_api_response():\n    with karva.snapshot_settings(filters=[\n        (r\"\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\", \"[timestamp]\"),\n        (r\"[0-9a-f-]{36}\", \"[uuid]\"),\n    ]):\n        karva.assert_snapshot(get_response())\n</code></pre> <p>Each filter is a <code>(regex_pattern, replacement)</code> tuple. Filters are applied sequentially to the serialized value before it is compared or stored in the snapshot file.</p>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#multiple-filters","level":3,"title":"Multiple Filters","text":"<p>When multiple filters are provided, they are applied in order. Earlier filters may affect what later filters see:</p> test.py<pre><code>import karva\n\ndef test_log_entry():\n    with karva.snapshot_settings(filters=[\n        (r\"\\d{4}-\\d{2}-\\d{2}\", \"[date]\"),\n        (r\"\\d+ms\", \"[duration]\"),\n    ]):\n        karva.assert_snapshot(\"2024-01-15: request completed in 42ms\")\n</code></pre> <p>The stored snapshot will contain: <code>[date]: request completed in [duration]</code>.</p>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#nested-settings","level":3,"title":"Nested Settings","text":"<p>Settings can be nested. Inner filters are appended to outer filters, so all filters from the entire stack apply:</p> test.py<pre><code>import karva\n\ndef test_complex_output():\n    with karva.snapshot_settings(filters=[(r\"\\d+ms\", \"[duration]\")]):\n        with karva.snapshot_settings(filters=[(r\"/tmp/\\S+\", \"[path]\")]):\n            karva.assert_snapshot(\"took 42ms at /tmp/abc123\")\n</code></pre> <p>The stored snapshot will contain: <code>took [duration] at [path]</code>.</p>","path":["Snapshots"],"tags":[]},{"location":"usage/snapshots/#inline-snapshots","level":3,"title":"Inline Snapshots","text":"<p>Filters also work with inline snapshots. The filtered value is what gets compared and stored:</p> test.py<pre><code>import karva\n\ndef test_inline_filtered():\n    with karva.snapshot_settings(filters=[(r\"\\d{4}-\\d{2}-\\d{2}\", \"[date]\")]):\n        karva.assert_snapshot(\"event on 2024-01-15\", inline=\"event on [date]\")\n</code></pre>","path":["Snapshots"],"tags":[]},{"location":"usage/fixtures/builtin/","level":1,"title":"Builtin","text":"<p>Karva provides a few built-in fixtures that can be used in your tests.</p> <p>We will try to add more built-in fixtures from pytest in the future.</p>","path":["Using Karva","Fixtures","Builtin"],"tags":[]},{"location":"usage/fixtures/builtin/#temporary-directory","level":2,"title":"Temporary Directory","text":"<p>This fixture provides the user with a <code>pathlib.Path</code> object that points to a temporary directory.</p> <p>You can use any of the following fixture names:</p> <ul> <li><code>tmp_path</code> (from pytest)</li> <li><code>tmpdir</code> (from pytest)</li> <li><code>temp_path</code> (from karva)</li> <li><code>temp_dir</code> (from karva)</li> </ul> test.py<pre><code>def test_tmp_path(tmp_path):\n    assert tmp_path.is_dir()\n</code></pre>","path":["Using Karva","Fixtures","Builtin"],"tags":[]},{"location":"usage/fixtures/builtin/#mock-environment","level":2,"title":"Mock Environment","text":"<p>This fixture allows you to safely modify environment variables, and the system path during tests. All changes are automatically undone after the test completes.</p> <p>You can use any of the following fixture names:</p> <ul> <li><code>monkeypatch</code> (from pytest)</li> </ul> <p>This fixture is compatible with pytest's <code>monkeypatch</code> fixture.</p> test.py<pre><code>def test_setattr(monkeypatch):\n    import os\n    monkeypatch.setattr(os, 'getcwd', lambda: '/fake/path')\n    assert os.getcwd() == '/fake/path'\n\ndef test_setenv(monkeypatch):\n    monkeypatch.setenv('MY_VAR', 'test_value')\n    import os\n    assert os.environ['MY_VAR'] == 'test_value'\n</code></pre> <p>The fixture provides all of these helper methods:</p> Python<pre><code>monkeypatch.setattr(obj, name, value, raising=True)\nmonkeypatch.delattr(obj, name, raising=True)\nmonkeypatch.setitem(mapping, name, value)\nmonkeypatch.delitem(obj, name, raising=True)\nmonkeypatch.setenv(name, value, prepend=False)\nmonkeypatch.delenv(name, raising=True)\nmonkeypatch.syspath_prepend(path)\nmonkeypatch.chdir(path)\n</code></pre> <p>The raising parameter determines whether or not a <code>KeyError</code> or <code>AttributeError</code> is raised when the attribute or item does not exist when trying to set / delete it.</p>","path":["Using Karva","Fixtures","Builtin"],"tags":[]},{"location":"usage/fixtures/builtin/#simple-example","level":3,"title":"Simple Example","text":"<p>Consider a scenario where you are working with user configuration and you need to mock their cache directory.</p> test.py<pre><code>from pathlib import Path\n\n\ndef get_cache_dir():\n    \"\"\"Returns the user's cache directory.\"\"\"\n    return Path.home() / \".cache\"\n\n\ndef test_get_cache_dir(monkeypatch):\n    monkeypatch.setattr(Path, \"home\", lambda: Path(\"/fake/home\"))\n\n    assert get_cache_dir() == Path(\"/fake/home/.cache\")\n</code></pre>","path":["Using Karva","Fixtures","Builtin"],"tags":[]},{"location":"usage/fixtures/builtin/#reusing-mocks","level":3,"title":"Reusing Mocks","text":"<p>we can share mocks across multiple functions without having to rerun the mocking functions by using fixture.</p> <p>See this example where instead of requesting the <code>monkeypatch</code> fixture, we can reuse the <code>mock_response</code> fixture.</p> <p>This lets us move the patching logic to another function and reuse the <code>mock_response</code> fixture across multiple tests.</p> Python<pre><code>import karva\nimport requests\n\n\nclass MockResponse:\n    def json(self):\n        return {\"mock_key\": \"mock_response\"}\n\n\ndef get_json(url):\n    \"\"\"Takes a URL, and returns the JSON.\"\"\"\n    r = requests.get(url)\n    return r.json()\n\n\n@karva.fixture\ndef mock_response(monkeypatch):\n    def mock_get(*args, **kwargs):\n        return MockResponse()\n\n    monkeypatch.setattr(requests, \"get\", mock_get)\n\n\ndef test_get_json(mock_response):\n    result = get_json(\"https://fakeurl\")\n    assert result[\"mock_key\"] == \"mock_response\"\n</code></pre>","path":["Using Karva","Fixtures","Builtin"],"tags":[]},{"location":"usage/fixtures/builtin/#mocking-environment-variables","level":3,"title":"Mocking Environment Variables","text":"<p>If you are working with environment variables, you often need to modify them when testing.</p> <p>See the example on how this could be useful.</p> Python<pre><code>import os\n\n\ndef get_num_threads() -&gt; int:\n    username = os.getenv(\"NUM_THREADS\")\n\n    if username is None:\n        return -1\n\n    return int(username)\n\n\ndef test_get_num_threads(monkeypatch):\n    monkeypatch.setenv(\"NUM_THREADS\", \"42\")\n    assert get_num_threads() == 42\n\n\ndef test_get_num_threads_default(monkeypatch):\n    monkeypatch.delenv(\"NUM_THREADS\", raising=False)\n    assert get_num_threads() == -1\n</code></pre> <p>See the pytest documentation for more information.</p>","path":["Using Karva","Fixtures","Builtin"],"tags":[]},{"location":"usage/fixtures/fixtures/","level":1,"title":"Fixtures","text":"<p>Fixtures provide a mechanism for setup and teardown logic in tests. They enable dependency injection, allowing tests to declare their dependencies explicitly and receive them automatically.</p>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/fixtures/fixtures/#defining-fixtures","level":2,"title":"Defining Fixtures","text":"<p>Define a fixture using the <code>@karva.fixture</code> decorator:</p> test.py<pre><code>import karva\n\n@karva.fixture\ndef database_connection():\n    return create_connection()\n\ndef test_query(database_connection):\n    result = database_connection.execute(\"SELECT 1\")\n    assert result == 1\n</code></pre>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/fixtures/fixtures/#fixture-scopes","level":2,"title":"Fixture Scopes","text":"<p>Fixtures support different scopes that control their lifecycle and when they are created and destroyed.</p>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/fixtures/fixtures/#function-scope-default","level":3,"title":"Function Scope (Default)","text":"<p>The fixture is created and destroyed for each test function that uses it:</p> test.py<pre><code>import karva\n\n@karva.fixture\ndef counter():\n    return {\"count\": 0}\n\ndef test_first(counter):\n    counter[\"count\"] += 1\n    assert counter[\"count\"] == 1\n\ndef test_second(counter):\n    # Fresh instance, count is 0 again\n    assert counter[\"count\"] == 0\n</code></pre>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/fixtures/fixtures/#module-scope","level":3,"title":"Module Scope","text":"<p>The fixture is created once per test module and shared across all tests in that module:</p> test.py<pre><code>import karva\n\n@karva.fixture(scope=\"module\")\ndef shared_resource():\n    print(\"Creating resource\")\n    return ExpensiveResource()\n</code></pre>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/fixtures/fixtures/#package-scope","level":3,"title":"Package Scope","text":"<p>The fixture is created once per package (directory). Each sub-package that contains tests using the fixture receives its own instance.</p> <p>Consider the following directory structure:</p> Text Only<pre><code>tests/\n├── conftest.py\n├── unit/\n│   └── test_unit.py\n└── integration/\n    └── test_integration.py\n</code></pre> tests/conftest.py<pre><code>import karva\n\n@karva.fixture(scope=\"package\")\ndef package_resource():\n    return create_resource()\n</code></pre> <p>If both <code>test_unit.py</code> and <code>test_integration.py</code> use <code>package_resource</code>, the fixture is instantiated once for <code>unit/</code> and once for <code>integration/</code>.</p>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/fixtures/fixtures/#session-scope","level":3,"title":"Session Scope","text":"<p>The fixture is created once for the entire test session and shared across all tests:</p> conftest.py<pre><code>import karva\n\n@karva.fixture(scope=\"session\")\ndef global_config():\n    return load_configuration()\n</code></pre>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/fixtures/fixtures/#dynamic-scope","level":3,"title":"Dynamic Scope","text":"<p>The scope can be determined at runtime using a callable:</p> conftest.py<pre><code>import karva\nimport os\n\ndef determine_scope(fixture_name: str, config: object) -&gt; str:\n    if os.environ.get(\"CI\"):\n        return \"session\"\n    return \"function\"\n\n@karva.fixture(scope=determine_scope)\ndef adaptive_fixture():\n    return create_resource()\n</code></pre> <p>The callable receives <code>fixture_name</code> as a string and <code>config</code> (currently <code>None</code>).</p>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/fixtures/fixtures/#dependent-fixtures","level":2,"title":"Dependent Fixtures","text":"<p>Fixtures can depend on other fixtures, enabling composition:</p> conftest.py<pre><code>import karva\n\n@karva.fixture\ndef base_url():\n    return \"https://api.example.com\"\n\n@karva.fixture\ndef api_client(base_url):\n    return APIClient(base_url)\n\n@karva.fixture\ndef authenticated_client(api_client):\n    api_client.authenticate()\n    return api_client\n</code></pre> test.py<pre><code>def test_api_call(authenticated_client):\n    response = authenticated_client.get(\"/users\")\n    assert response.status_code == 200\n</code></pre>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/fixtures/fixtures/#teardown-with-generators","level":2,"title":"Teardown with Generators","text":"<p>Use generator fixtures to implement teardown logic. Code after <code>yield</code> executes after the fixture's scope ends:</p> conftest.py<pre><code>import karva\nimport shutil\n\n@karva.fixture\ndef database():\n    db = create_database()\n    yield db\n    db.close()\n\n@karva.fixture(scope=\"module\")\ndef temp_directory():\n    path = create_temp_dir()\n    yield path\n    shutil.rmtree(path)\n</code></pre> <p>Example output when running with <code>karva test --show-output</code>:</p> Text Only<pre><code>Creating database\nRunning test\nClosing database\n</code></pre>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/fixtures/fixtures/#auto-use-fixtures","level":2,"title":"Auto-Use Fixtures","text":"<p>Auto-use fixtures execute automatically for all tests within their scope, without requiring explicit declaration:</p> conftest.py<pre><code>import karva\nimport logging\n\n@karva.fixture(auto_use=True)\ndef setup_logging():\n    logging.basicConfig(level=logging.DEBUG)\n    yield\n    logging.shutdown()\n</code></pre> test.py<pre><code>def test_something():\n    # setup_logging runs automatically before this test\n    pass\n</code></pre> <p>This is particularly useful for global setup and teardown:</p> conftest.py<pre><code>import karva\n\n@karva.fixture(scope=\"session\", auto_use=True)\ndef database_migrations():\n    run_migrations()\n    yield\n    rollback_migrations()\n</code></pre>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/fixtures/fixtures/#use-fixtures-tag","level":2,"title":"Use-Fixtures Tag","text":"<p>The <code>use_fixtures</code> tag explicitly declares fixture dependencies when no return value is needed:</p> conftest.py<pre><code>import karva\n\n@karva.fixture\ndef setup_cache():\n    initialize_cache()\n    yield\n    clear_cache()\n\n@karva.fixture\ndef seed_data():\n    insert_test_data()\n</code></pre> test.py<pre><code>import karva\n\n@karva.tags.use_fixtures(\"setup_cache\", \"seed_data\")\ndef test_cached_query():\n    result = query_with_cache()\n    assert result is not None\n</code></pre>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/fixtures/fixtures/#overriding-fixtures","level":2,"title":"Overriding Fixtures","text":"<p>Fixtures can be overridden in nested directories. The overriding fixture can reference the parent fixture:</p> conftest.py<pre><code>import karva\n\n@karva.fixture\ndef username():\n    return \"default_user\"\n</code></pre> test_default.py<pre><code>def test_default_user(username):\n    assert username == \"default_user\"\n</code></pre> admin/conftest.py<pre><code>import karva\n\n@karva.fixture\ndef username(username):\n    return f\"admin_{username}\"\n</code></pre> admin/test_admin.py<pre><code>def test_admin_user(username):\n    assert username == \"admin_default_user\"\n</code></pre>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/fixtures/fixtures/#limitations","level":2,"title":"Limitations","text":"<p>Karva does not support the <code>request</code> fixture. This is an intentional design decision and there are no plans to add support for it.</p>","path":["Using Karva","Fixtures"],"tags":[]},{"location":"usage/tags/expect_fail/","level":1,"title":"Expect fail","text":"<p>The <code>expect_fail</code> tag is used to mark a test as expected to fail. When a test marked with <code>expect_fail</code> fails, it is considered a success. When a test marked with <code>expect_fail</code> passes, it is considered a failure.</p>","path":["Using Karva","Tags","Expect fail"],"tags":[]},{"location":"usage/tags/expect_fail/#basic-usage","level":2,"title":"Basic Usage","text":"test.py<pre><code>import karva\n\n@karva.tags.expect_fail\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one passed test.</p> test.py<pre><code>import karva\n\n@karva.tags.expect_fail()\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one passed test.</p>","path":["Using Karva","Tags","Expect fail"],"tags":[]},{"location":"usage/tags/expect_fail/#reason","level":2,"title":"Reason","text":"<p>You can provide a <code>str</code> reason as a positional or keyword argument.</p> test.py<pre><code>import karva\n\n@karva.tags.expect_fail(\"This test is expected to fail\")\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one passed test.</p> test.py<pre><code>import karva\n\n@karva.tags.expect_fail(reason=\"This test is expected to fail\")\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one passed test.</p> <p>The reason only shows when the test passes when expected to fail.</p> test.py<pre><code>import karva\n\n@karva.tags.expect_fail(reason=\"This test is expected to fail\")\ndef test_function():\n    assert True\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one failed test.</p>","path":["Using Karva","Tags","Expect fail"],"tags":[]},{"location":"usage/tags/expect_fail/#pytest","level":2,"title":"Pytest","text":"<p>We can also still use <code>@pytest.mark.xfail</code>.</p> test.py<pre><code>import pytest\n\n@pytest.mark.xfail(reason=\"This test is expected to fail\")\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one passed test.</p>","path":["Using Karva","Tags","Expect fail"],"tags":[]},{"location":"usage/tags/expect_fail/#conditions","level":2,"title":"Conditions","text":"<p>We can provide <code>bool</code> conditions as a positional arguments.</p> <p>Then the test will only be expected to fail if all conditions are <code>True</code>.</p> test.py<pre><code>import karva\n\n@karva.tags.expect_fail(True)\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one passed test.</p> <p>You can still provide a reason as a keyword argument.</p> test.py<pre><code>import karva\n\n@karva.tags.expect_fail(True, reason=\"Waiting for feature X to be implemented\")\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one passed test.</p>","path":["Using Karva","Tags","Expect fail"],"tags":[]},{"location":"usage/tags/expect_fail/#multiple-conditions","level":3,"title":"Multiple Conditions","text":"test.py<pre><code>import karva\n\n@karva.tags.expect_fail(True, False)\ndef test_function():\n    assert True\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one failed test.</p>","path":["Using Karva","Tags","Expect fail"],"tags":[]},{"location":"usage/tags/parametrize/","level":1,"title":"Parametrize","text":"<p>The <code>parametrize</code> tag allows us to run the same test with several different inputs.</p> <p>This works like pytest's <code>parametrize</code> decorator.</p>","path":["Using Karva","Tags","Parametrize"],"tags":[]},{"location":"usage/tags/parametrize/#basic-usage","level":2,"title":"Basic Usage","text":"<p>First, here is a small example:</p> test.py<pre><code>import karva\n\n@karva.tags.parametrize(\"a\", [1, 2, 3])\ndef test_function(a: int):\n    assert a &gt; 0\n</code></pre> <p>Then running <code>uv run karva test</code> will provide the following output:</p> Text Only<pre><code>test test::test_function(a=1) ... ok\ntest test::test_function(a=2) ... ok\ntest test::test_function(a=3) ... ok\n\ntest result: ok. 3 passed; 0 failed; 0 skipped; finished in 0s\n</code></pre>","path":["Using Karva","Tags","Parametrize"],"tags":[]},{"location":"usage/tags/parametrize/#multiple-variables","level":2,"title":"Multiple Variables","text":"<p>We can also parametrize multiple arguments:</p> test.py<pre><code>import karva\n\n@karva.tags.parametrize((\"a\", \"b\"), [(1, 4), (2, 5), (3, 6)])\ndef test_function(a: int, b: int):\n    assert a &gt; 0 and b &gt; 0\n</code></pre> <p>Then running <code>uv run karva test</code> will provide the following output:</p> Text Only<pre><code>test test::test_function(a=1, b=4) ... ok\ntest test::test_function(a=2, b=5) ... ok\ntest test::test_function(a=3, b=6) ... ok\n\ntest result: ok. 3 passed; 0 failed; 0 skipped; finished in 0s\n</code></pre> <p>Like pytest, we can put the arguments in a single string, separated by \",\".</p> test.py<pre><code>import karva\n\n@karva.tags.parametrize(\"a,b\", [(1, 4), (2, 5), (3, 6)])\ndef test_function(a: int, b: int):\n    assert a &gt; 0 and b &gt; 0\n</code></pre> <p>Then running <code>uv run karva test</code> will provide the following output:</p> Text Only<pre><code>test test::test_function(a=1, b=4) ... ok\ntest test::test_function(a=2, b=5) ... ok\ntest test::test_function(a=3, b=6) ... ok\n\ntest result: ok. 3 passed; 0 failed; 0 skipped; finished in 0s\n</code></pre>","path":["Using Karva","Tags","Parametrize"],"tags":[]},{"location":"usage/tags/parametrize/#parametrize-with-fixtures","level":2,"title":"Parametrize with Fixtures","text":"<p>We can also mix fixtures and parametrize:</p> test.py<pre><code>import karva\n\n@karva.fixture\ndef b() -&gt; int:\n    return 1\n\n@karva.tags.parametrize(\"a\", [1, 2])\ndef test_function(a: int, b: int):\n    assert a &gt; 0 and b &gt; 0\n</code></pre> <p>Then running <code>uv run karva test -v</code> will provide the following output:</p> Text Only<pre><code>test test::test_function(a=1, b=1) ... ok\ntest test::test_function(a=2, b=1) ... ok\n\ntest result: ok. 2 passed; 0 failed; 0 skipped; finished in 0s\n</code></pre>","path":["Using Karva","Tags","Parametrize"],"tags":[]},{"location":"usage/tags/parametrize/#multiple-parametrize-tags","level":2,"title":"Multiple Parametrize Tags","text":"<p>We can also use multiple decorators, allowing us to test more scenarios.</p> <p>This will result in a cartesian product of the parametrize values.</p> test.py<pre><code>import karva\n\n@karva.tags.parametrize(\"a\", [1, 2])\n@karva.tags.parametrize(\"b\", [1, 2])\ndef test_function(a: int, b: int):\n    assert a &gt; 0 and b &gt; 0\n</code></pre> <p>Then running <code>uv run karva test -v</code> will provide the following output:</p> Text Only<pre><code>test test::test_function(a=1, b=1) ... ok\ntest test::test_function(a=2, b=1) ... ok\ntest test::test_function(a=1, b=2) ... ok\ntest test::test_function(a=2, b=2) ... ok\n\ntest result: ok. 4 passed; 0 failed; 0 skipped; finished in 0s\n</code></pre>","path":["Using Karva","Tags","Parametrize"],"tags":[]},{"location":"usage/tags/parametrize/#params","level":2,"title":"Params","text":"<p>You can use <code>karva.param</code> (similar to <code>pytest.param</code>) for parameters.</p> test.py<pre><code>import karva\n\n@karva.tags.parametrize(\"input,expected\", [\n    karva.param(2, 4),\n    karva.param(4, 17, tags=(karva.tags.skip,)),\n    karva.param(5, 26, tags=(karva.tags.expect_fail,)),\n    karva.param(6, 36, tags=(karva.tags.skip(True),)),\n    karva.param(7, 50, tags=(karva.tags.expect_fail(True),)),\n])\ndef test_square(input, expected):\n    assert input ** 2 == expected\n</code></pre> <p>Then running <code>uv run karva test -v</code> will provide the following output:</p> Text Only<pre><code>test tests.test_add::test_square(expected=4, input=2) ... ok\ntest tests.test_add::test_square ... skipped\ntest tests.test_add::test_square(expected=26, input=5) ... ok\ntest tests.test_add::test_square ... skipped\ntest tests.test_add::test_square(expected=50, input=7) ... ok\n\ntest result: ok. 3 passed; 0 failed; 2 skipped; finished in 0ms\n</code></pre>","path":["Using Karva","Tags","Parametrize"],"tags":[]},{"location":"usage/tags/parametrize/#pytest","level":2,"title":"Pytest","text":"<p>You can also still use <code>@pytest.mark.parametrize</code>.</p> test.py<pre><code>import pytest\n\n@pytest.mark.parametrize(\"a\", [1, 2])\ndef test_function(a: int):\n    assert a &gt; 0\n</code></pre> <p>Then running <code>uv run karva test -v</code> will provide the following output:</p> Text Only<pre><code>test test::test_function(a=1) ... ok\ntest test::test_function(a=2) ... ok\n\ntest result: ok. 2 passed; 0 failed; 0 skipped; finished in 0s\n</code></pre>","path":["Using Karva","Tags","Parametrize"],"tags":[]},{"location":"usage/tags/skip/","level":1,"title":"Skip","text":"<p>The <code>skip</code> tag allows us to mark test functions to be skipped during test execution.</p> <p>When a test is skipped, it will not be run but will be counted in the test results.</p>","path":["Using Karva","Tags","Skip"],"tags":[]},{"location":"usage/tags/skip/#basic-usage","level":2,"title":"Basic Usage","text":"test.py<pre><code>import karva\n\n@karva.tags.skip\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one skipped test.</p> test.py<pre><code>import karva\n\n@karva.tags.skip()\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one skipped test.</p>","path":["Using Karva","Tags","Skip"],"tags":[]},{"location":"usage/tags/skip/#reason","level":2,"title":"Reason","text":"<p>You can provide a <code>str</code> reason as a positional or keyword argument.</p> test.py<pre><code>import karva\n\n@karva.tags.skip(\"This test is not implemented yet\")\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one skipped test.</p> test.py<pre><code>import karva\n\n@karva.tags.skip(reason=\"Waiting for feature X to be implemented\")\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one skipped test.</p>","path":["Using Karva","Tags","Skip"],"tags":[]},{"location":"usage/tags/skip/#pytest","level":2,"title":"Pytest","text":"<p>You can also still use <code>@pytest.mark.skip</code>.</p> test.py<pre><code>import pytest\n\n@pytest.mark.skip(reason=\"Waiting for feature X to be implemented\")\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one skipped test.</p>","path":["Using Karva","Tags","Skip"],"tags":[]},{"location":"usage/tags/skip/#conditions","level":2,"title":"Conditions","text":"<p>We can provide <code>bool</code> conditions as a positional arguments.</p> <p>Then the test will only be skipped if all conditions are <code>True</code>.</p> test.py<pre><code>import karva\n\n@karva.tags.skip(True)\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one skipped test.</p> <p>You can still provide a reason as a keyword argument.</p> test.py<pre><code>import karva\n\n@karva.tags.skip(True, reason=\"Waiting for feature X to be implemented\")\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one skipped test.</p>","path":["Using Karva","Tags","Skip"],"tags":[]},{"location":"usage/tags/skip/#multiple-conditions","level":3,"title":"Multiple Conditions","text":"test.py<pre><code>import karva\n\n@karva.tags.skip(True, False) # This will not be skipped\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one failed test.</p>","path":["Using Karva","Tags","Skip"],"tags":[]},{"location":"usage/tags/skip/#pytest_1","level":3,"title":"Pytest","text":"<p>You can also still use <code>@pytest.mark.skipif</code>.</p> test.py<pre><code>import pytest\n\n@pytest.mark.skipif(True, reason=\"Waiting for feature X to be implemented\")\ndef test_function():\n    assert False\n</code></pre> <p>Then running <code>uv run karva test</code> will result in one skipped test.</p>","path":["Using Karva","Tags","Skip"],"tags":[]}]}